#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Dec  5 15:48:09 2023

@author: claudiacaudai
"""


class dataset_sampler:
    'Docstring'
    
    import numpy as np
    import pandas as pd
    import os
    import argparse
    import copy


    def __init__(self):
        self.M_dataset_properties = None, 
        self.M_correlation = None, 
        self.M_shape_colours_prob = None,
        self.dictionary = None
        
        import argparse
        
        '''
        dataset_properties = None : csv file with dataset properties
        '''

    
    
        parser = argparse.ArgumentParser()
        # arguments
        parser.add_argument("-s", "--shapes", help="array with desired shapes (defined by number of vertices, es circle=0, triangle=3, square=4, etc...)", type=float,default=[0,3])
        parser.add_argument("-c", "--colours", help="array with desired colours (defined by rgb values, es red=[1,0,0], green=[0,1,0], blue=[0,0,1], etc...)", type=float, default=[[1,0,0]])
        parser.add_argument("-ps", "--prob_shapes", help="array with probabilities of shapes (sum must be 1).", type=float, default=[0.5,0.5])
        parser.add_argument("-pc", "--prob_colours", help="earray with probabilities of colours (sum must be 1).", type=float, default=[1])
        parser.add_argument("-centx", "--centre_x", help="lower bound, upper bound, average and sigma of distribution of x coord of centres (in percentage in respect to x axis).", type=float, default=[None,None,50,None])
        parser.add_argument("-centy", "--centre_y", help="lower bound, upper bound, average and sigma of distribution of y coord of centres (in percentage in respect to y axis).", type=float, default=[None,None,50,None])
        parser.add_argument("-rad", "--radius", help="lower bound, upper bound, average and sigma of distribution of radii (in percentage in respect to x axis).", type=float, default=[None,None,10,None])
        parser.add_argument("-rot", "--rotation", help="lower bound, upper bound, average and sigma of distribution of rotations (in degrees).", type=float, default=[None,None,0,None])
        parser.add_argument("-def", "--deformation", help="lower bound, upper bound, average and sigma of distribution of deformations (percentage of curvature of edges, 100=circle).", type=float, default=[None,None,0,None])
        parser.add_argument("-blur", "--blur", help="lower bound, upper bound, average and sigma of distribution of blur (in strength, from 0=no noise to 100=max noise).", type=float, default=[None,None,0,None])
        parser.add_argument("-wn", "--white_noise", help="lower bound, upper bound, average and sigma of distribution of white noise (in strength, from 0=no noise to 100=max noise).", type=float, default=[None,None,0,None])
        parser.add_argument("-ho", "--holes", help="lower bound, upper bound, average and sigma of distribution of holes noise (in strength, from 0=no noise to 100=max noise).", type=float, default=[None,None,0,None])
        parser.add_argument("-anr", "--additive_noise_regression", help="lower bound, upper bound, average and sigma of distribution of amount of additive random error (in strength, from 0=no noise to 100=max noise).", type=float, default=[None,None,0,None])
        parser.add_argument("-mnr", "--multiplicative_noise_regression", help="lower bound, upper bound, average and sigma of distribution of amount of multiplicative random error  (in strength, from 0=no noise to 100=max noise).", type=float, default=[None,None,0,None])
        parser.add_argument("-name", "--outputs_folder_name", help='name of outputs folder', type=str, default="dataset_csv_files")
        parser.add_argument("-d_name", "--dataset_name", help='Name of the dataset', type=str, default="standard")
        parser.add_argument("-d_size", "--dataset_size", help='Number of images generated by NA_DAtabase package.', type=int, default = 1000)
        parser.add_argument("-sampl", "--sampling_strategy", help='Sampling strategy: random Monte Carlo (MC), Latin Hypercube Sampling (LHC), and quasi-random low discrepancy sequence (LDS)', type=str, default='MC')
        parser.add_argument("-rand_s", "--random_seed", help='Random seed to guarantee reproducibility.', type=int, default=1902)
        parser.add_argument("-pr_x", "--pixel_resolution_x", help='Number of pixels on the x-axis.', type=int, default=120)
        parser.add_argument("-pr_y", "--pixel_resolution_y", help='Number of pixels on the y-axis.', type=int, default=120)
        parser.add_argument("-class", "--correct_classes", help='Define the correct class. A class is given by a shape (e.g., 3) followed by a color (e.g., (0,1,0)). An empty field corresponds to a null condition on color/shape (e.g. 3/ corresponds to all triangles, /(1,1,1) to all white figures).\
                            Each row correspond to a further class marked as correct.', type=list, default =['1/'])
        parser.add_argument("-bg_col", "--background_color", help='Background image/color. Can be a color string (i.e., (1,0,0), (1,1,1), etc.) or a path to an image.', type=float, default=[0,0,0])
        parser.add_argument("-oob", "--out_of_border", help='If true, pictures containing out of border shapes are allowed. If false, these pictures are resampled. resampling can be applied only to standard Monte Carlo sampling approach', type=bool, default=True)
        parser.add_argument("-c_noise" , "--classification_noise", help='Is a list of classification noises to be applied to the original pictures. Each noise is described by 3 values: v1 ; v2 ; v3. v1 is the original class to be perturbed. Possibilities include:  \
                            a given class with a fixed color [3/(1,0,0)], an arbitrary shape with fixed color [/(1,0,0)], an arbitrary color with fixed shape [1/], or an arbitrary shape and color [/]. v2 is the perturbed class (v1 is converted to v2). \
                            Empty fields correspond to no modification, whereas * fields correspond to random resampling. v3 is the probability (in [0,1]) to apply classification noise.\
                            Examples:\
                            1) [/] ; [1/] ; 0.2 : with probability 0.2, each class is perturbed to shape 1 without color modification.\
                            2) [3/(1,1,1)] ; [4/] ; 0.3 : with probability 0.3, triangles with color (1,1,1) is perturbed to shape 4 without color modification.\
                            3)  [3/(1,1,1)] ; [4/*] ; 0.3 : with probability 0.3, triangles with color (1,1,1) is perturbed to shape 4 with a totally random color.', type=list, default = [])

        
        
        #%%
        
        
        
        
        args = parser.parse_args()
        
        self.dictionary = {'shapes': args.shapes, 
             'colours' : args.colours,
             'prob_shapes': args.prob_shapes,
             'prob_colours': args.prob_colours,
             'centre_x': args.centre_x,
             'centre_y': args.centre_y,
             'radius': args.radius,
             'rotation': args.rotation,
             'deformation': args.deformation,
             'blur': args.blur,
             'white_noise': args.white_noise,
             'holes': args.holes,
             'additive_noise_regression': args.additive_noise_regression,
             'multiplicative_noise_regression': args.multiplicative_noise_regression,
             'outputs_folder_name': args.outputs_folder_name,
             'dataset_name':args.dataset_name,
             'dataset_size':args.dataset_size,
             'sampling_strategy':args.sampling_strategy,
             'random_seed':args.random_seed,
             'pixel_resolution_x':args.pixel_resolution_x,
             'pixel_resolution_y':args.pixel_resolution_y,
             'correct_classes':args.correct_classes,
             'background_color':args.background_color,
             'out_of_border':args.out_of_border,
             'classification_noise':args.classification_noise
            }
    
        
        self.keys_prop = ['centre_x','centre_y','radius','rotation','deformation','blur','white_noise','holes','additive_noise_regression','multiplicative_noise_regression']
        self.keys_sampler = ['dataset_name','dataset_size','sampling_strategy','random_seed','pixel_resolution_x','pixel_resolution_y','correct_classes','background_color','out_of_border','classification_noise']
        self.create_matrices()
        
        for key in self.keys_prop:
            self.control(key)
        
    # create_matrices() creates M_dataset_properties the datset_properties matrix, the shape and colours mutual probabilities matrix,
    # the matrix of correlation between features, for every colour and shape, and the sampler_properties matrix.       
    def create_matrices(self):
        import numpy as np
        import pandas as pd
        
        rows=pd.Index(['low_b','up_b','mu','sigma'])
        self.M_dataset_properties = {key: self.dictionary[key] for key in self.keys_prop}
        self.M_dataset_properties = pd.DataFrame(data=self.M_dataset_properties, index=rows)
        
        data_sampler = {'dataset_name':[self.dictionary['dataset_name']],
        'dataset_size':[self.dictionary['dataset_size']],
        'sampling_strategy':[self.dictionary['sampling_strategy']],
        'random_seed':[self.dictionary['random_seed']],
        'pixel_resolution_x':[self.dictionary['pixel_resolution_x']],
        'pixel_resolution_y':[self.dictionary['pixel_resolution_y']],
        'correct_classes':[self.dictionary['correct_classes']],
        'background_color':[self.dictionary['background_color']],
        'out_of_border':[self.dictionary['out_of_border']],
        'classification_noise':[self.dictionary['classification_noise']]}
        self.M_sampler_properties = pd.DataFrame(data=data_sampler)
        
        self.M_shape_colours_prob=np.zeros((len(self.dictionary['prob_colours']),len(self.dictionary['prob_shapes'])))
        for i in range(len(self.dictionary['prob_shapes'])):
            for j in range(len(self.dictionary['prob_colours'])):
                self.M_shape_colours_prob[j,i]=self.dictionary['prob_shapes'][i]*self.dictionary['prob_colours'][j]

        self.M_correlation=np.zeros((self.M_dataset_properties.shape[1]*len(self.dictionary['shapes']), self.M_dataset_properties.shape[1]*len(self.dictionary['colours'])))
        for i in range(len(self.dictionary['shapes'])):
            for j in range(len(self.dictionary['colours'])):
                for z in range(self.M_dataset_properties.shape[1]):
                    self.M_correlation[z+i*self.M_dataset_properties.shape[1],z+j*self.M_dataset_properties.shape[1]]=1
                    
        
    # save_data() saves dataset_properties.csv, shapes_colors_probabilities.csv and dataset_correlation.csv' 
    def save_data(self):
        
        import numpy as np
        import pandas as pd
        import os
    
        path_data = os.getcwd()
        path_save_folder = os.path.join(path_data, self.dictionary['outputs_folder_name'])
        if not os.path.isdir(path_save_folder):
            os.mkdir(path_save_folder) 
        
        self.M_dataset_properties = pd.DataFrame(data=self.M_dataset_properties)
        self.M_dataset_properties.to_csv(os.path.join(path_save_folder,'dataset_properties.csv'))
        
        self.M_sampler_properties = pd.DataFrame(data=self.M_sampler_properties)
        self.M_sampler_properties.to_csv(os.path.join(path_save_folder,'sampler_properties.csv'),index=False)
        
        rows=pd.Index(self.dictionary['colours'])
        columns=pd.Index(self.dictionary['shapes'])
        self.M_shape_colours_prob=pd.DataFrame(self.M_shape_colours_prob,rows, columns)
        self.M_shape_colours_prob.to_csv(os.path.join(path_save_folder,'shapes_colors_probabilities.csv'))

        np.savetxt(os.path.join(path_save_folder,'dataset_correlation.csv'),self.M_correlation,delimiter=",")

    # contro() verifies that distributions are admitted and defines them
    def control(self,name):
        
        if (self.dictionary[name][0]!=None and self.dictionary[name][1]!=None and self.dictionary[name][0] < self.dictionary[name][1] and (self.dictionary[name][2]==None or self.dictionary[name][3]==None)):
            print("Uniform Distribution")  
        elif (self.dictionary[name][0]==None and self.dictionary[name][1]==None and self.dictionary[name][2]!=None and self.dictionary[name][3]!=None and self.dictionary[name][3]>0):
            print("Gaussian Distribution") 
        elif (self.dictionary[name][0]==None and self.dictionary[name][1]==None and self.dictionary[name][2]!=None and self.dictionary[name][3]==None):
            print("Constant Distribution")
        elif (((self.dictionary[name][0]!=None and self.dictionary[name][1]!=None and self.dictionary[name][0]<self.dictionary[name][1]) or\
              (self.dictionary[name][0]!=None and self.dictionary[name][1]==None) or\
              (self.dictionary[name][0]==None and self.dictionary[name][1]!=None)) and self.dictionary[name][2]!=None and self.dictionary[name][3]>0):
            print("Truncated Gaussian Distribution")
        else:
            print("warning: invalid distribution")
    
    # ater() changes the values of the keys in the disctionary
    def alter(self,name,value):
        
        try: 
            len(value)==len(self.dictionary[name])
        except ValueError:
            print('set correct value format')  
        name=str(name)
        self.dictionary[name]=value
        if name in self.keys_prop:
            self.control(name)
        self.create_matrices()
    
    
    def set_prob_standard(self,name):
        
        # name can be 'shapes' or 'colours'
        try:
            name =='colours' or name == 'shapes'
        except ValueError:
            print('name must be shapes or colours')
        self.dictionary[str('prob_'+name)]=[]
        for i in range(len(self.dictionary[name])):
            prob_c=1/len(self.dictionary[name])
            self.dictionary[str('prob_'+name)].append(prob_c)
        self.create_matrices()
    
    
    def set_prob_fix(self, name, values, probs):
        import numpy as np
        
        if type(values[0])!=list:
            values=[values]
        if type(probs)!=list:
            probs=[probs]
        try:
            len(values)==len(probs)
        except ValueError:
            print('values and probs must have same length')
        try:
            name =='colours' or name == 'shapes'
        except ValueError:
            print('name must be shapes or colours')
        try:
            for i in range(len(values)):
                values[i] in self.dictionary[name]
        except ValueError:
            print('the value is not in the string')
        self.dictionary[str('prob_'+name)]=[]
        for i in range(len(self.dictionary[name])):
            for j in range(len(values)):
                if self.dictionary[name][i] == values[j]:
                    prob_c = probs[j]
                    self.dictionary[str('prob_'+name)].append(prob_c)
                else:
                    if len(self.dictionary[name])!=len(values):
                        prob_c=round(1-np.sum(probs)/(len(self.dictionary[name])-len(values)),2)
                        self.dictionary[str('prob_'+name)].append(prob_c)
        self.create_matrices()
                        
    
    def set_correl(self,prop1,prop2,p):
        try:
            prop1 in self.keys_prop
        except ValueError:
            print('the key is not in the dictionary')
        try:
            prop2 in self.keys_prop
        except ValueError:
            print('the key is not in the dictionary')
            
        p1=list(self.keys_prop).index(prop1)
        p2=list(self.keys_prop).index(prop2)
        for i in range(len(self.dictionary['colours'])):
            for j in range(len(self.dictionary['shapes'])):
                self.M_correlation[p1+j*self.M_dataset_properties.shape[1],p2+i*self.M_dataset_properties.shape[1]]=p
                self.M_correlation[p2+j*self.M_dataset_properties.shape[1],p1+i*self.M_dataset_properties.shape[1]]=p
        self.create_matrices()         
            

            
    # controllo sui raggi, devono essere limitati, occorre mettere un bound al centro pari a [raggio, centro-raggio]
    
    
    



